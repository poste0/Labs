{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(image, prob):\n",
    "    r, g, b = cv2.split(image)\n",
    "    def make_noise_channel(channel):\n",
    "        channel_prob = prob / image.shape[2]\n",
    "        result_channel = channel.copy()\n",
    "        for i in range(channel.shape[0]):\n",
    "            for j in range(channel.shape[1]):\n",
    "                rand = np.random.randint(0, 101)\n",
    "                if rand <= channel_prob:\n",
    "                    result_channel[i, j] += np.random.randint(0, 256) % 256\n",
    "        \n",
    "        return result_channel\n",
    "    \n",
    "    result_r = make_noise_channel(r)\n",
    "    result_g = make_noise_channel(g)\n",
    "    result_b = make_noise_channel(b)\n",
    "    \n",
    "    result = cv2.merge((result_r, result_g, result_b))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def convol_image(image, mask):\n",
    "    offset_x = int(mask.shape[0] / 2)\n",
    "    offset_y = int(mask.shape[1] / 2)\n",
    "    def conv_elem(i, j):\n",
    "        result = 0\n",
    "        for k in range(mask.shape[0]):\n",
    "            for l in range(mask.shape[1]):\n",
    "                result += image[i - offset_x + k, j - offset_y + l] * mask[k, l]\n",
    "        return result\n",
    "    result = np.zeros(image.shape)\n",
    "    for i in range(offset_x, result.shape[0] - offset_x - 2):\n",
    "        for j in range(offset_y, result.shape[1] - offset_y - 2):\n",
    "            result[i + 2, j + 2] = conv_elem(i, j) \n",
    "    return (result * 255 / np.max(result)).astype('int32')\n",
    "\n",
    "def corr(A, B, k, l):\n",
    "    rows = A.shape[0]\n",
    "    cols = A.shape[1]\n",
    "    result = None\n",
    "    if k < 0 and l < 0:\n",
    "        return np.sum(np.sum(A[0:rows - abs(k), 0:cols - abs(l)] * B[abs(k):rows, abs(l):cols])) / (\n",
    "                (rows - 1) * (cols - 1))\n",
    "\n",
    "    elif k < 0 and l >= 0:\n",
    "        return np.sum(np.sum(A[0:rows - abs(k), l:cols] * B[abs(k):rows, 0:cols - l])) / ((rows - 1) * (cols - 1))\n",
    "\n",
    "    elif k >= 0 and l < 0:\n",
    "        return np.sum(np.sum(A[k:rows, 0:cols - abs(l)] * B[0:rows - k, abs(l):cols])) / ((rows - 1) * (cols - 1))\n",
    "\n",
    "    return np.sum(np.sum(A[k:rows, l:cols] * B[0:rows - k, 0:cols - l])) / ((rows - 1) * (cols - 1))\n",
    "\n",
    "def get_b(image, image_noise, D):\n",
    "    b = np.zeros(len(D) ** 2)\n",
    "    i = 0\n",
    "    \n",
    "    for k in D:\n",
    "        for l in D:\n",
    "            b[i] = corr(image, image_noise, -k + 100, -l + 200)\n",
    "            i += 1\n",
    "    return b\n",
    "\n",
    "def get_A(image, D):\n",
    "    size = len(D) ** 2\n",
    "    result = np.zeros((size, size))\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    for k in D:\n",
    "        for l in D:\n",
    "            for n in D:\n",
    "                for m in D:\n",
    "                    result[i, j] = corr(image, image, k - n + 100, l - m + 200)\n",
    "                    j += 1\n",
    "            i += 1\n",
    "            j = 0\n",
    "    return result\n",
    "\n",
    "def get_x(A, b):\n",
    "    return np.linalg.solve(A, b).reshape(int(np.sqrt(b.shape)), int(np.sqrt(b.shape)))\n",
    "\n",
    "def filter_image(image, image_noise, D, suffix):\n",
    "    r, g, b = cv2.split(image)\n",
    "\n",
    "    file = suffix\n",
    "    \n",
    "    image_noise_r, image_noise_g, image_noise_b = cv2.split(image_noise)\n",
    "    \n",
    "    cv2.imwrite(path + file + '_noise.jpg', image_noise)\n",
    "    cv2.imwrite(path + file + '_r.jpg', r)\n",
    "    cv2.imwrite(path + file + '_g.jpg', g)\n",
    "    cv2.imwrite(path + file + '_b.jpg', b)\n",
    "    cv2.imwrite(path + file + '_r_noise.jpg', image_noise_r)\n",
    "    cv2.imwrite(path + file + '_g_noise.jpg', image_noise_g)\n",
    "    cv2.imwrite(path + file + '_b_noise.jpg', image_noise_b)\n",
    "\n",
    "    A_r = get_A(image_noise_r, D)\n",
    "    A_g = get_A(image_noise_g, D)\n",
    "    A_b = get_A(image_noise_b, D)\n",
    "\n",
    "    b_r = get_b(r, image_noise_r, D)\n",
    "    b_g = get_b(g, image_noise_g, D)\n",
    "    b_b = get_b(b, image_noise_b, D)\n",
    "\n",
    "    x_r = get_x(A_r, b_r)\n",
    "    x_g = get_x(A_g, b_g)\n",
    "    x_b = get_x(A_b, b_b)\n",
    "    \n",
    "    print(x_r)\n",
    "    print(x_g)\n",
    "    print(x_b)\n",
    "\n",
    "    result_r = convol_image(r, np.abs(x_r))\n",
    "    result_g = convol_image(g, np.abs(x_g))\n",
    "    result_b = convol_image(b, np.abs(x_b))\n",
    "\n",
    "    cv2.imwrite(path + file + '_filter_r.jpg', result_r)\n",
    "    cv2.imwrite(path + file + '_filter_g.jpg', result_g)\n",
    "    cv2.imwrite(path + file + '_filter_b.jpg', result_b)\n",
    "\n",
    "    result = cv2.merge((result_r, result_g, result_b))\n",
    "    \n",
    "    print(np.min(result))\n",
    "    print(np.max(result))\n",
    "\n",
    "    cv2.imwrite(path + file + '_filter.jpg', result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_error(image, filtered_image):\n",
    "    image = image / 255\n",
    "    filtered_image = filtered_image / 255\n",
    "    difference = (image[5: - 5, 5: - 5] - filtered_image[5: - 5, 5: - 5]) ** 2\n",
    "    \n",
    "    return (np.sum(difference) / (image.shape[0] * image.shape[1] * image.shape[2])) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/sergei/Laba5/'\n",
    "D = [-3, -2, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Протестировать фильтрацию на изображении из пункта 1, осуществив КИХ-фильтрацию с использованием маски, вычисленной на основе методики, описанной в пунктах 3-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_no_noise_image = cv2.imread(path + 'obama.jpg')\n",
    "\n",
    "obama_no_noise_filtered_image = filter_image(obama_no_noise_image, obama_no_noise_image, D, 'obama_no_noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Повторить пункт 6 для того же изображения, предварительно зашумив его с вероятностью искажения p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_noise_image = cv2.imread(path + 'obama.jpg')\n",
    "obama_noise_image_noise = make_noise(obama_noise_image, 9)\n",
    "\n",
    "obama_noise_filtered_image = filter_image(obama_noise_image, obama_noise_image_noise, D, 'obama_noise')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Осуществить зашумление тестовых изображений из пункта 2 с вероятностью искажения пикселя . Осуществить КИХ фильтрацию изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.40985545  2.31542418 -0.27877279]\n",
      " [ 2.28236885  0.10779014 -3.23941297]\n",
      " [ 3.97385077 -4.31628848 -2.23872978]]\n",
      "[[ 17.82645697  20.6668944   23.14913395]\n",
      " [ -5.669799     7.9607459  -17.51685733]\n",
      " [-18.95581285 -18.80413738  -7.55031675]]\n",
      "[[-0.21583864 -1.30464774  2.12642255]\n",
      " [ 3.52105597  0.2660331   0.63085891]\n",
      " [-1.25442722  1.2486001  -4.0152277 ]]\n",
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "lukashenko_image = cv2.imread(path + 'lukashenko.jpg')\n",
    "lukashenko_image_noise = make_noise(lukashenko_image, 9)\n",
    "\n",
    "lukashenko_filtered_image = filter_image(lukashenko_image, lukashenko_image_noise, D, 'lukashenko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2037.13392991 -1185.71862952  -597.13882649]\n",
      " [ 2297.17475007  1252.39855536 -2590.85425151]\n",
      " [  369.30919647  -758.43493016  -766.93269655]]\n",
      "[[ 11.32654046   9.53945227 -10.55501144]\n",
      " [  0.94774794  -3.71460761  16.61163109]\n",
      " [  0.24788532  13.92997304 -36.98818857]]\n",
      "[[  9.0057816   -4.59614634   8.75642031]\n",
      " [ -1.59480266   4.04667799   1.48650483]\n",
      " [ -2.56640989  -1.28757715 -12.13859822]]\n",
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "bicycle_image = cv2.imread(path + 'bicycle.jpg')\n",
    "bicycle_image_noise = make_noise(bicycle_image, 15)\n",
    "\n",
    "bicycle_filtered_image = filter_image(bicycle_image, bicycle_image_noise, D, 'bicycle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вычислить ошибку восстановления сигнала для всех трёх изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for obama no noise 10.168436539628958\n"
     ]
    }
   ],
   "source": [
    "print('Error for obama no noise {}'.format(get_error(obama_no_noise_image, obama_no_noise_filtered_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for obama noise 10.168436539628958\n"
     ]
    }
   ],
   "source": [
    "print('Error for obama noise {}'.format(get_error(obama_noise_image, obama_noise_filtered_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for lukashenko 0.0323512508061224\n"
     ]
    }
   ],
   "source": [
    "print('Error for lukashenko {}'.format(get_error(lukashenko_image, lukashenko_filtered_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bicycle 0.37587144491692154\n"
     ]
    }
   ],
   "source": [
    "print('Error for bicycle {}'.format(get_error(bicycle_image, bicycle_filtered_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bicycle 0.09129717623967037\n"
     ]
    }
   ],
   "source": [
    "print('Error for bicycle {}'.format(get_error(bicycle_image, bicycle_image_noise)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for lukashenko 0.07306316384076471\n"
     ]
    }
   ],
   "source": [
    "print('Error for lukashenko {}'.format(get_error(lukashenko_image, lukashenko_image_noise)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
